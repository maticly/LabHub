# ğŸ§ª LabHub â€” Inventory Intelligence Platform
*A full OLTP â†’ OLAP warehouse with ETL, Data Quality, semantic search, and a Streamlit analytics dashboard.*

---

## ğŸ“Œ Overview

LabHub is a complete data engineering project that simulates a real-world inventory intelligence system. It includes:

- **SQL Server OLTP** database (core product, user, vendor, inventory tables)  
- **DuckDB OLAP warehouse** with a Kimball-style star schema  
- **Python ETL pipeline** (dimensions, facts, DQ gatekeeper, rollback logic)  
- **Data Quality framework** with critical/warning checks  
- **Semantic search** using ChromaDB + embeddings  
- **Streamlit dashboard** for KPIs and inventory insights  
- **Documentation, diagrams, and SQL build scripts**

This project demonstrates modern data engineering practices: incremental loads, DQ enforcement, warehouse orchestration, and vector search integration.

---

## ğŸ—ï¸ Architecture
```mermaid
SQL Server (OLTP)
        â†“
Python ETL Pipeline
        â†“
Data Quality Gatekeeper
        â†“
DuckDB Warehouse (OLAP)
        â†“
Streamlit Dashboard + Vector Search
```

---

## ğŸ“ Project Structure


```mermaid
LabHub_final_CS779/
â”œâ”€â”€ analytics/                     # Backend data logic (ETL, warehouse, connections)
â”‚   â”œâ”€â”€ data/                      # DB connectors + generated OLTP seed data
â”‚   â”‚   â”œâ”€â”€ connect_db.py          # Connectors for OLTP (SQL Server) & OLAP (DuckDB)
â”‚   â”‚   â”œâ”€â”€ generated_data_OLTP/   # Synthetic OLTP CSVs used to populate SQL Server
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ etl/                       # Full ETL pipeline (dimensions, facts, DQ, orchestration)
â”‚   â”‚   â”œâ”€â”€ run_pipeline.py        # Main warehouse pipeline orchestrator
â”‚   â”‚   â”œâ”€â”€ data_quality.py        # Data Quality checks (DQ gatekeeper)
â”‚   â”‚   â”œâ”€â”€ old_etl_inventory.py   # Legacy ETL (kept for reference)
â”‚   â”‚   â”œâ”€â”€ dimensions/            # Dimension ETL modules
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_date.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_location.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_product.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_user.py
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ facts/                 # Fact table ETL modules
â”‚   â”‚   â”‚   â”œâ”€â”€ fact_inventory.py
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ __pycache__/           # Python cache files
â”‚   â”‚
â”‚   â”œâ”€â”€ warehouse/                 # Warehouse initialization + view creation
â”‚   â”‚   â”œâ”€â”€ init_warehouse.py      # Creates schemas, tables, and seeds warehouse
â”‚   â”‚   â”œâ”€â”€ create_views.py        # Builds analytics views (KPI-ready)
â”‚   â”‚   â”œâ”€â”€ warehouse.duckdb       # DuckDB OLAP database file
â”‚   â”‚   â”œâ”€â”€ warehouse_schema.sql   # SQL schema for warehouse
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ app/                           # Streamlit application (UI layer)
â”‚   â”œâ”€â”€ main_dashboard.py          # Main dashboard entrypoint
â”‚   â”œâ”€â”€ components.py              # Reusable UI components
â”‚   â”œâ”€â”€ inventory_helpers.py       # Helper functions for dashboard logic
â”‚   â”œâ”€â”€ styles.py                  # Custom CSS styling
â”‚   â”‚
â”‚   â”œâ”€â”€ streamlit/                 # Streamlit config
â”‚   â”‚   â””â”€â”€ config.toml
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                        # UI modules (KPIs, layout, navigation)
â”‚   â”‚   â”œâ”€â”€ kpi.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ chroma_db/                     # Vector database for semantic search
â”‚   â”œâ”€â”€ chroma.sqlite3             # ChromaDB metadata
â”‚   â””â”€â”€ <uuid>/                    # Vector index shards
â”‚
â”œâ”€â”€ config/                        # Global configuration files (placeholder)
â”‚
â”œâ”€â”€ docs/                          # Documentation & diagrams
â”‚   â”œâ”€â”€ architecture_diagram.png   # System architecture diagram
â”‚   â”œâ”€â”€ oltp_to_olap_mapping.md    # Mapping between OLTP and OLAP schemas
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ sql db/                        # SQL Server OLTP schema + seed scripts
â”‚   â”œâ”€â”€ CS779_LabHub_final.sql     # Full OLTP database build script
â”‚   â””â”€â”€ CS779_LabHub_db/           # Modular SQL scripts (tables, constraints, seeds)
â”‚
â”œâ”€â”€ static/                        # Static assets for UI
â”‚   â””â”€â”€ logo.png
â”‚
â””â”€â”€ vector/                        # Vector search logic (embeddings + retrieval)
    â”œâ”€â”€ search.py
    â”œâ”€â”€ vector_store.py
    â””â”€â”€ __init__.py

```

---


## â­ Dimensional Model (Mermaid Diagram)

```mermaid
erDiagram
    DIM_PRODUCT {
        int ProductKey PK
        int ProductID
        string ProductName
        string CategoryName
        string UnitOfMeasure
        string Description
    }

    DIM_USER {
        int UserKey PK
        int UserID
        string UserName
        string Role
    }

    DIM_LOCATION {
        int LocationKey PK
        int LocationID
        string LocationName
        string Region
    }

    DIM_DATE {
        int DateKey PK
        date FullDate
        int Year
        int Month
        int Day
        string DayOfWeek
    }

    FACT_INVENTORY_TRANSACTIONS {
        int TransactionKey PK
        int ProductKey FK
        int UserKey FK
        int LocationKey FK
        int DateKey FK
        int AbsoluteQuantity
        string TransactionType
    }

    FACT_INVENTORY_TRANSACTIONS ||--|| DIM_PRODUCT : "ProductKey"
    FACT_INVENTORY_TRANSACTIONS ||--|| DIM_USER : "UserKey"
    FACT_INVENTORY_TRANSACTIONS ||--|| DIM_LOCATION : "LocationKey"
    FACT_INVENTORY_TRANSACTIONS ||--|| DIM_DATE : "DateKey"
```

---

## ğŸ”„ ETL Pipeline
1. Dimension Loads
- **Date**
- **Product**
- **User**
- **Location**

2. Fact Load
- **Incremental load of inventory transactions**
- **Skips rows already present in OLAP**

3. Data Quality Gatekeeper
Checks include:
- **Negative stock**
- **Orphaned foreign keys**
- **Duplicate transaction IDs**
- **Missing product descriptions**
- **Freshness (todayâ€™s data present)**

DQ Logic
- **If all PASS/WARN â†’ COMMIT**
- **If any FAIL â†’ move fact load to staging + ROLLBACK**

## ğŸ“Š Streamlit Dashboard
The dashboard provides:
- **Inventory KPIs**
- **Stock movement trends**
- **Product-level insights**
- **Semantic search powered by ChromaDB**
- **Clean UI with custom styling**

Run it with:

```bash
streamlit run app/main_dashboard.py
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
| :--- | :--- |
| **OLTP** | SQL Server |
| **OLAP** | DuckDB |
| **ETL** | Python (Pandas, DuckDB, PyODBC) |
| **DQ** | Custom Python framework |
| **UI** | Streamlit |
| **Vector Search** | ChromaDB |
| **Modeling** | Kimball (Star Schema) |


---

## ğŸš€ Running the Pipeline
```bash
python -m analytics.etl.run_pipeline
```

This will:
- **Load dimensions**
- **Load facts**
- **Run DQ**
- **Commit or rollback**
- **Refresh analytics views**